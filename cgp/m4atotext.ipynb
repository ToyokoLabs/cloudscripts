{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instal ffmpeg\n",
    "sudo apt-get install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo pip install pydub\n",
    "!sudo pip install google-cloud-speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from pydub import AudioSegment\n",
    "from google.cloud import speech_v1\n",
    "from google.cloud.speech_v1 import enums\n",
    "from google.cloud import storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def m4a_2_wav(m4a_bucket, wav_bucket):\n",
    "    \"\"\"\n",
    "    Converts all m4a in a bucket to a wav in copy to another bucket\n",
    "    \"\"\"\n",
    "    ori_ext = '.m4a'\n",
    "    tmp_name = 'file.m4a'\n",
    "    \n",
    "    \n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(m4a_bucket)\n",
    "\n",
    "    blobs = bucket.list_blobs()\n",
    "    for blob in blobs:\n",
    "        print(blob.name)\n",
    "        if blob.name.endswith(ori_ext):\n",
    "            with open(tmp_name, 'wb') as fh:\n",
    "                blob.download_to_file(fh)\n",
    "            track = AudioSegment.from_file(tmp_name, 'm4a')\n",
    "            file_handle = track.export('file.wav', format='wav')\n",
    "            # copy to bucket\n",
    "            bucket_out = client.get_bucket(wav_bucket)        \n",
    "            filename, _ = os.path.splitext(blob.name)\n",
    "            blob_new_name = filename + '.wav'\n",
    "            blob = bucket_out.blob(blob_new_name)\n",
    "            blob.upload_from_filename(filename='file.wav')\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(bucket, blob, sample_rate_hertz=48000, language_code='es-ES'):\n",
    "    \"\"\"\n",
    "    Get one wav blob and con\n",
    "    \"\"\"\n",
    "    client = speech_v1.SpeechClient()\n",
    "    # This field is optional for FLAC and WAV audio formats.\n",
    "    encoding = enums.RecognitionConfig.AudioEncoding.LINEAR16\n",
    "    metadata = {\n",
    "        \"original_media_type\": enums.RecognitionMetadata.OriginalMediaType.AUDIO,\n",
    "        \"original_mime_type\": 'audio/m4a',}\n",
    "    config = {\n",
    "        \"metadata\": metadata,\n",
    "        \"audio_channel_count\": 2,\n",
    "        \"language_code\": language_code,\n",
    "        \"enable_separate_recognition_per_channel\": True,\n",
    "        }\n",
    "    audio = {\"uri\": \"gs://{}/{}\".format(bucket, blob)}\n",
    "    print(\"gs://{}/{}\".format(bucket, blob))\n",
    "    operation = client.long_running_recognize(config, audio)\n",
    "    print(u\"Waiting for operation to complete...{}\".format(language_code))\n",
    "    return operation.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transcribe_bucket(bucket_name, language_code='es-ES'):\n",
    "    \"\"\"\n",
    "    Transcribe all wav files from a bucket\n",
    "    \"\"\"\n",
    "\n",
    "    tmp_pickle_name = 'data.pickle'\n",
    "\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs()\n",
    "    for blob in blobs:\n",
    "        # check for pickle version\n",
    "        filename, _ = os.path.splitext(blob.name)\n",
    "        pickled_name = filename + '.pickle'\n",
    "        if blob.name.endswith('.wav') and not bucket.blob(pickled_name).exists():\n",
    "            # Generate transcription\n",
    "            transcribed = get_text(bucket.name, blob.name, language_code=language_code)\n",
    "            # Upload raw output to a pickle\n",
    "            with open(tmp_pickle_name, 'wb') as fh:\n",
    "                # Pickle the transcription using the highest protocol available.\n",
    "                pickle.dump(transcribed, fh)\n",
    "            blob = bucket.blob(pickled_name)\n",
    "            blob.upload_from_filename(tmp_pickle_name)\n",
    "        else:\n",
    "            print(\"no transcription will be done for: {}\".format(blob.name))\n",
    "        # Generate clear text\n",
    "        #break\n",
    "    logging.warning('DONE')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcript_object_2_text_file(t_obj, filename):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    channel_1 = ''\n",
    "    channel_2 = ''\n",
    "    for result in t_obj.results:\n",
    "        #print(result)\n",
    "        if result.channel_tag == 1:\n",
    "            channel_1 += result.alternatives[0].transcript + ' '\n",
    "        elif result.channel_tag == 2:\n",
    "            channel_2 += result.alternatives[0].transcript + ' '\n",
    "    outtext = 'Transcribed Text: \\n\\nChannel 1: '\n",
    "    outtext += channel_1 + '\\n---\\nChannel 2: '\n",
    "    outtext += channel_2 + '\\n'\n",
    "    with open(filename, 'w') as fh:\n",
    "        fh.write(outtext)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pickle to text\n",
    "\n",
    "def batch_pickle_2_text(bucket):\n",
    "    \"\"\"\n",
    "    Convert all pickle files into text\n",
    "    \"\"\"\n",
    "    tmp_txt_name = 'tmp.txt'\n",
    "    tmp_pickle_name = 'tmp.pickle'\n",
    "\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(bucket)\n",
    "\n",
    "    blobs = bucket.list_blobs()\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith('.pickle'):\n",
    "            # download\n",
    "            with open(tmp_pickle_name, 'wb') as fh:\n",
    "                blob.download_to_file(fh)\n",
    "            # \n",
    "            with open(tmp_pickle_name, 'rb') as fh:\n",
    "                #pickle_obj = fh.read()\n",
    "                obj = pickle.load(fh)\n",
    "            transcript_object_2_text_file(obj, tmp_txt_name)\n",
    "            filename, _ = os.path.splitext(blob.name)\n",
    "            filename += '.txt'\n",
    "            blob = bucket.blob(filename)\n",
    "            blob.upload_from_filename(tmp_txt_name)\n",
    "    logging.warning(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run conversion\n",
    "\n",
    "out_bucket = \"audioout_es-es\"\n",
    "\n",
    "m4a_2_wav(\"original_audios\", out_bucket)\n",
    "transcribe_bucket(out_bucket, 'es-ES')\n",
    "batch_pickle_2_text(out_bucket)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
